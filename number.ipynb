{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 115s 10us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (60000, 28, 28) (60000,)\n",
      "Testing data shape :  (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape : ',x_train.shape , y_train.shape)\n",
    "\n",
    "print('Testing data shape : ', x_test.shape , y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(y_train)\n",
    "print('Output classes : ', classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'num 1 : 7')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=[5,5])\n",
    "plt.subplot(121)\n",
    "plt.imshow(x_train[0,:,:], cmap='gray')\n",
    "plt.title(\"num 1 : {}\".format(y_train[0]))\n",
    "plt.subplot(122)\n",
    "plt.imshow(x_test[0,:,:], cmap='gray')\n",
    "plt.title(\"num 1 : {}\".format(y_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train= x_train.reshape(-1, 28,28, 1)\n",
    "x_test= x_test.reshape(-1, 28,28, 1)\n",
    "x_train.shape, x_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After conversion to one-hot encoding: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train= x_train/ 255.\n",
    "x_test= x_test/ 255.\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "print('After conversion to one-hot encoding:', y_train_one_hot[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_valid,train_label,valid_label = train_test_split(x_train,y_train_one_hot, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/computer/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "number_model = Sequential()\n",
    "number_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(28,28,1),padding='same'))\n",
    "number_model.add(LeakyReLU(alpha=0.1))\n",
    "number_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "number_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "number_model.add(LeakyReLU(alpha=0.1))\n",
    "number_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "number_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "number_model.add(LeakyReLU(alpha=0.1))                  \n",
    "number_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "number_model.add(Flatten())\n",
    "number_model.add(Dense(128, activation='linear'))\n",
    "number_model.add(LeakyReLU(alpha=0.1))                  \n",
    "number_model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 356,234\n",
      "Trainable params: 356,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "number_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/computer/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 110s 2ms/step - loss: 0.1635 - acc: 0.9489 - val_loss: 0.0601 - val_acc: 0.9805\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 113s 2ms/step - loss: 0.0437 - acc: 0.9861 - val_loss: 0.0455 - val_acc: 0.9858\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 118s 2ms/step - loss: 0.0302 - acc: 0.9902 - val_loss: 0.0401 - val_acc: 0.9883\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 117s 2ms/step - loss: 0.0221 - acc: 0.9928 - val_loss: 0.0343 - val_acc: 0.9892\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 119s 2ms/step - loss: 0.0167 - acc: 0.9947 - val_loss: 0.0393 - val_acc: 0.9894\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 121s 3ms/step - loss: 0.0142 - acc: 0.9953 - val_loss: 0.0383 - val_acc: 0.9906\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 114s 2ms/step - loss: 0.0136 - acc: 0.9955 - val_loss: 0.0329 - val_acc: 0.9918\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 115s 2ms/step - loss: 0.0095 - acc: 0.9971 - val_loss: 0.0396 - val_acc: 0.9890\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 123s 3ms/step - loss: 0.0103 - acc: 0.9969 - val_loss: 0.0365 - val_acc: 0.9908\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 116s 2ms/step - loss: 0.0094 - acc: 0.9968 - val_loss: 0.0457 - val_acc: 0.9901\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 120s 2ms/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0398 - val_acc: 0.9904\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 117s 2ms/step - loss: 0.0081 - acc: 0.9975 - val_loss: 0.0402 - val_acc: 0.9901\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 122s 3ms/step - loss: 0.0048 - acc: 0.9984 - val_loss: 0.0519 - val_acc: 0.9900\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 118s 2ms/step - loss: 0.0088 - acc: 0.9972 - val_loss: 0.0453 - val_acc: 0.9888\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 116s 2ms/step - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0415 - val_acc: 0.9915\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 120s 3ms/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.0481 - val_acc: 0.9906\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 120s 2ms/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0456 - val_acc: 0.9911\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 120s 2ms/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0507 - val_acc: 0.9919\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 120s 3ms/step - loss: 0.0069 - acc: 0.9981 - val_loss: 0.0395 - val_acc: 0.9921\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 121s 3ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0515 - val_acc: 0.9912\n"
     ]
    }
   ],
   "source": [
    "number_train = number_model.fit(x_train, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_valid, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.3868925983428957\n",
      "Test accuracy: 0.1135\n"
     ]
    }
   ],
   "source": [
    "test_eval = number_model.evaluate(x_test, y_test_one_hot, verbose=0)\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "number_model = Sequential()\n",
    "number_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(28,28,1)))\n",
    "number_model.add(LeakyReLU(alpha=0.1))\n",
    "number_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "number_model.add(Dropout(0.25))\n",
    "number_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "number_model.add(LeakyReLU(alpha=0.1))\n",
    "number_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "number_model.add(Dropout(0.25))\n",
    "number_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "number_model.add(LeakyReLU(alpha=0.1))                  \n",
    "number_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "number_model.add(Dropout(0.4))\n",
    "number_model.add(Flatten())\n",
    "number_model.add(Dense(128, activation='linear'))\n",
    "number_model.add(LeakyReLU(alpha=0.1))           \n",
    "number_model.add(Dropout(0.3))\n",
    "number_model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 356,234\n",
      "Trainable params: 356,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "number_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 110s 2ms/step - loss: 2.3019 - acc: 0.1111 - val_loss: 13.1969 - val_acc: 0.1008\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 114s 2ms/step - loss: 0.8396 - acc: 0.6992 - val_loss: 3.7692 - val_acc: 0.7641\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 117s 2ms/step - loss: 0.1682 - acc: 0.9469 - val_loss: 2.4375 - val_acc: 0.8465\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 118s 2ms/step - loss: 0.1216 - acc: 0.9618 - val_loss: 1.6205 - val_acc: 0.8973\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 120s 3ms/step - loss: 0.1000 - acc: 0.9681 - val_loss: 1.6700 - val_acc: 0.8945\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 121s 3ms/step - loss: 0.0865 - acc: 0.9743 - val_loss: 2.1824 - val_acc: 0.8630\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 126s 3ms/step - loss: 0.0770 - acc: 0.9761 - val_loss: 2.3080 - val_acc: 0.8551\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 123s 3ms/step - loss: 0.0696 - acc: 0.9782 - val_loss: 1.3494 - val_acc: 0.9153\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 122s 3ms/step - loss: 0.0642 - acc: 0.9797 - val_loss: 1.3446 - val_acc: 0.9147\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 120s 3ms/step - loss: 0.0575 - acc: 0.9818 - val_loss: 1.2567 - val_acc: 0.9211\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 121s 3ms/step - loss: 0.0555 - acc: 0.9821 - val_loss: 0.6532 - val_acc: 0.9585\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 126s 3ms/step - loss: 0.0528 - acc: 0.9827 - val_loss: 0.4791 - val_acc: 0.9698\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 124s 3ms/step - loss: 0.0484 - acc: 0.9848 - val_loss: 0.8155 - val_acc: 0.9487\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 126s 3ms/step - loss: 0.0467 - acc: 0.9852 - val_loss: 0.7763 - val_acc: 0.9511\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 123s 3ms/step - loss: 0.0428 - acc: 0.9858 - val_loss: 0.6474 - val_acc: 0.9593\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 120s 3ms/step - loss: 0.0431 - acc: 0.9864 - val_loss: 0.4038 - val_acc: 0.9746\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 119s 2ms/step - loss: 0.0402 - acc: 0.9865 - val_loss: 0.5113 - val_acc: 0.9677\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 119s 2ms/step - loss: 0.0389 - acc: 0.9873 - val_loss: 0.5421 - val_acc: 0.9660\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 123s 3ms/step - loss: 0.0378 - acc: 0.9874 - val_loss: 0.5079 - val_acc: 0.9678\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 129s 3ms/step - loss: 0.0356 - acc: 0.9888 - val_loss: 0.5901 - val_acc: 0.9631\n"
     ]
    }
   ],
   "source": [
    "number_train_dropout = number_model.fit(x_train , train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_valid, valid_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 421us/step\n"
     ]
    }
   ],
   "source": [
    "test_eval = number_model.evaluate(x_test, y_test_one_hot, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.024877145380353977\n",
      "Test accuracy: 0.991\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
